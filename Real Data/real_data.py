# -*- coding: utf-8 -*-
"""Real Data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10Yyouj-32zDLAMg31vT8zg6O20zICkd0
"""

!pip install pulp

import pandas as pd

# Load the Excel file
file_path = '/content/Book1.xlsx'
excel_data = pd.ExcelFile(file_path)

sheet_names = excel_data.sheet_names
print(sheet_names)

df = excel_data.parse(sheet_names[0])
print(df.head())

print(df.info())
print(df.describe())

df = df.dropna()
df['Weight'] = df['Weight'].astype(float)
df['PRICE'] = df['PRICE'].astype(float)

df['FA TAT'] = df['FA TAT'].str.replace('+', '').astype(float)  # Remove '+' and convert to int

df['lbh'] = df['lbh'].astype(str)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder

# Define features and target variables
features = ['SourceWH', 'State', 'Ext Transporter', 'Weight', 'Length', 'Breadth', 'Height']
X = df[features]
y_price = df['PRICE']

# Convert 'FA TAT' to datetime objects if they are not already, handling errors
df['FA TAT'] = pd.to_datetime(df['FA TAT'], errors='coerce')

# Calculate minimum TAT for subtraction (after handling potential NaTs)
min_tat = df['FA TAT'].min()  # Find the minimum TAT value first
y_tat = df['FA TAT'].apply(lambda x: (x - min_tat).days if pd.notnull(x) else None)  # Handle NaTs

# Handle categorical features (One-Hot Encoding for 'State', 'SourceWH', and 'Ext Transporter')
ohe = OneHotEncoder(handle_unknown='ignore')  # 'ignore' to handle new categories in test data
X_encoded = ohe.fit_transform(X[['State', 'SourceWH', 'Ext Transporter']]) # Include 'Ext Transporter' in encoding

# Convert sparse matrix to DataFrame for easier handling
X_encoded_df = pd.DataFrame.sparse.from_spmatrix(X_encoded)
# Get feature names for one-hot encoded columns
X_encoded_df.columns = ohe.get_feature_names_out(['State', 'SourceWH', 'Ext Transporter']) # Update feature names

X_other = X.drop(['State', 'SourceWH', 'Ext Transporter'], axis=1) # Drop encoded columns, no need to reset index
X_final = pd.concat([X_other, X_encoded_df], axis=1)  # Combine encoded and other features

# Align y_price with X_final after handling NaNs in y_tat
y_price = y_price[y_tat.notna()] # Subset y_price to match rows in X_final

# Drop rows with NaN in y_tat *after* creating X_final to ensure alignment
X_final = X_final[y_tat.notna()]
y_tat = y_tat[y_tat.notna()]

# Split the data (using the encoded features)
X_train, X_test, y_train_price, y_test_price = train_test_split(X_final, y_price, test_size=0.2, random_state=42)
X_train, X_test, y_train_tat, y_test_tat = train_test_split(X_final, y_tat, test_size=0.2, random_state=42)

# Train the models
price_model = LinearRegression().fit(X_train, y_train_price)
tat_model = LinearRegression().fit(X_train, y_train_tat)

# Make predictions
price_predictions = price_model.predict(X_test)
tat_predictions = tat_model.predict(X_test)

# Create a new DataFrame for predictions to avoid length mismatch
predictions_df = pd.DataFrame({
    'price_predictions': price_predictions,
    'tat_predictions': tat_predictions
}, index=X_test.index)  # Use the index of X_test

# Optionally, you can merge these predictions back into your original DataFrame 'df'
df = df.merge(predictions_df, how='left', left_index=True, right_index=True)

print(price_predictions)
print(tat_predictions)

from pulp import LpMinimize, LpProblem, LpVariable, lpSum

# Define a function to optimize and select the best courier
def optimize_courier(df, SourceWH, state):

    # Filter the data for the given warehouse and state
    filtered_df = df[(df['SourceWH'] == SourceWH) & (df['State'] == state)]

    # Handle potential NaN values in predictions
    filtered_df.fillna({'price_predictions': 0, 'tat_predictions': 0}, inplace=True)

    # Initialize the optimization problem
    model = LpProblem(name="courier-selection", sense=LpMinimize)

    # Create decision variables for each courier
    couriers = filtered_df['Ext Transporter'].unique()
    dec_vars = LpVariable.dicts("Ext Transporter", couriers, lowBound=0, cat='Binary')

    # Define the objective function: Minimize the sum of predicted price and TAT
    objective = lpSum([
        (filtered_df.loc[filtered_df['Ext Transporter'] == courier, 'price_predictions'].values[0] +
         filtered_df.loc[filtered_df['Ext Transporter'] == courier, 'tat_predictions'].values[0]) * dec_vars[courier]
        for courier in couriers
    ])
    model += objective

    # Add constraints: ensure only one courier is selected
    model += lpSum([dec_vars[courier] for courier in couriers]) == 1

    # Solve the problem
    status = model.solve() # Capture the status of the solver

    if status == 1: # 1 indicates an optimal solution was found
        best_courier = [v.name.replace("Ext Transporter_", "") for v in model.variables() if v.varValue is not None and v.varValue > 0]
        if best_courier:
            best_courier = best_courier[0]
        else:
            best_courier = "No feasible solution for any courier"
    else:
        best_courier = "No solution found" # Handle cases where no solution is found

    return best_courier

def get_best_courier(SourceWH, state):
    best_courier = optimize_courier(df, SourceWH, state)
    return best_courier

# Example usage
warehouse = 'Delhi/Gurgaon'  # Replace with actual warehouse
state = 'Madhya Pradesh'          # Replace with actual state

best_courier = get_best_courier(warehouse, state)
print(f"The best courier for {warehouse} to {state} is: {best_courier}")